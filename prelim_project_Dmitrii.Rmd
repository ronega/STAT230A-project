---
title: "project230A"
author: "Irina Degtiareva"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Created dummy variables

```{r}
library(dplyr)
library(fastDummies)

math <- read.csv("data/student-mat.csv", sep=";")
por <- read.csv("data/student-por.csv", sep=";")
por <- subset(por, select = -c(school, G1, G2))

pordumm <- dummy_cols(por, select_columns = c("sex", "address", "famsize", "Pstatus", "Medu",
                                              "Fedu", "Mjob", "Fjob", "reason", "guardian", 
                                              "traveltime", "studytime", "schoolsup", "famsup", 
                                              "paid", "activities", "nursery", "higher", "internet", 
                                              "romantic", "famrel", "freetime", "goout", 
                                              "Dalc", "Walc", "health"), 
                      remove_first_dummy = TRUE, 
                      remove_selected_columns = TRUE)
```

# Build model for the means within groups

```{r}
library(MASS)
library(car)

model_high <- lm(G3 ~ higher, data = por)
summary(model_high)
cat("HCCM Error for coef:", round(sqrt(hccm (model_high , type = "hc2" )[2 , 2]), 3))
```

# Save full model

```{r}
full_model <- lm(G3 ~., data = pordumm)
summary(full_model)

data_wout_h <- pordumm %>% dplyr::select(-higher_yes)
full_model_wout_h <- lm(G3 ~ ., data = data_wout_h)

beta <- full_model_wout_h$coefficients
```
Next steps:

1. Fit model $ Y\sim \beta_1 x_1+\beta_2 x_2+...+\beta_k x_k$ and choose variables
2. Fit model $ Z\sim \gamma_1 x_1+\gamma_2 x_2+...+\gamma_k x_k$ and choose variables

Why?
- Define all variables where we have connection between $Y$ and $x_i$; same for $Z$ and $x_i$ so we could remove bias in the final model.

# Variable Selection via Grouped Lasso for G3

```{r}
library(glmnet)
library(gglasso)

data <- pordumm %>% dplyr::select(-c('G3', 'higher_yes'))
X <- as.matrix(data)
y <- as.matrix(pordumm$G3)

group <- c(1, 2, 3, 4, 5, 6, 7, 
           8, 8, 8, 8, 
           9, 9, 9, 9, 
           10, 10, 10, 10, 
           11, 11, 11, 11, 
           12, 12, 12, 13, 
           13, 14, 
           14, 14, 
           15, 15, 15, 
           16, 17, 18, 19, 20, 21, 22, 
           23, 23, 23, 23, 
           24, 24, 24, 24, 
           25, 25, 25, 25, 
           26, 26, 26, 26, 
           27, 27, 27, 27, 
           28, 28, 28, 28)

lasso <- glmnet(X, y, lambda = 0.1,
                family="gaussian", alpha=1,
                intercept = TRUE)

# Just to show this is irrelevant
lasso <- cv.glmnet(X, y, aplha=1,
                   family="gaussian")
plot(lasso)
lasso$lambda.min

gr_lasso<- cv.gglasso(X, y, 
                      group = group,
                      pred.loss="L2",
                      loss="ls")

gr_lasso_fitted <- gglasso(X, y,
                           group = group,
                           lambda = gr_lasso$lambda.1se,
                           loss="ls")

coefs_z <- data.frame(
  z_initial = beta,
  z_gr_lasso = coef(gr_lasso_fitted)
)
names(coefs_z) <- c("z_initial", "z_from_gr_lasso")
```

# Variable Selection via Grouped Lasso for Y

```{r}
library(glmnet)
library(gglasso)

data <- pordumm %>% dplyr::select(-c('G3', 'higher_yes'))
X <- as.matrix(data)
y <- as.matrix(pordumm$higher_yes)
group <- c(1, 2, 3, 4, 5, 6, 7, 
           8, 8, 8, 8, 
           9, 9, 9, 9, 
           10, 10, 10, 10, 
           11, 11, 11, 11, 
           12, 12, 12, 13, 
           13, 14, 
           14, 14, 
           15, 15, 15, 
           16, 17, 18, 19, 20, 21, 22, 
           23, 23, 23, 23, 
           24, 24, 24, 24, 
           25, 25, 25, 25, 
           26, 26, 26, 26, 
           27, 27, 27, 27, 
           28, 28, 28, 28)

lasso <- glmnet(X, y, lambda = 0.1,
                family="gaussian", alpha=1,
                intercept = TRUE)

# Just to show this is irrelevant
lasso <- cv.glmnet(X, y, aplha=1,
                   family="gaussian")
plot(lasso)
lasso$lambda.min

gr_lasso<- cv.gglasso(X, y, 
                      group = group,
                      pred.loss="L2",
                      loss="ls")

gr_lasso_fitted <- gglasso(X, y,
                           group = group,
                           lambda = gr_lasso$lambda.1se,
                           loss="ls")

coefs_y <- data.frame(
  y_initial = beta,
  y_gr_lasso = coef(gr_lasso_fitted)
)
names(coefs_y) <- c("y_initial", "y_from_gr_lasso")
```

# Combine coefs

```{r}
all_coefs <- cbind(coefs_y, coefs_z)
all_coefs$union <- all_coefs$y_from_gr_lasso != 0 | all_coefs$z_from_gr_lasso != 0
all_coefs %>% filter(union == TRUE)
```

```{r}
final_data <- por %>% dplyr::select('age', 'failures', 'absences', 
                                    'sex', 'address', 'Medu', 'internet', 
                                    'higher', 'G3')

final_data <- dummy_cols(final_data, select_columns = c("sex", "address", "Medu", 
                                                 "internet", 'higher'),
                         remove_selected_columns = TRUE,
                         remove_first_dummy = TRUE)


summary(lm(G3 ~ ., data=final_data))$coefficients
summary(full_model)$coefficients

confint(lm(G3 ~ ., data=final_data))
```